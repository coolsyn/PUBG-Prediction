{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pubg-finish-placement-prediction/sample_submission_V2.csv\n",
      "/kaggle/input/pubg-finish-placement-prediction/train_V2.csv\n",
      "/kaggle/input/pubg-finish-placement-prediction/test_V2.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import matplotlib.pyplot as plt\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train_raw=pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')\n",
    "#read data_set from kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw=df_train_raw[df_train_raw['kills']<=30]\n",
    "#clean the data,we assume the kill>30 are cheating in the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import sklearn\n",
    "#import some lib\n",
    "df=df_train_raw.drop(columns=['Id','groupId','matchId','matchType'])\n",
    "#drop some rows that are not going to be used in the training\n",
    "df=df.sample(n=100000)\n",
    "#choose 100,000 columns randomly to train our model\n",
    "#for we do not have plenty of time to train our model in GPU, we just select a small batch of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 6.250e-02]\n",
      " [0.000e+00 4.000e+00 3.031e+02 ... 3.000e+00 1.470e+03 8.571e-01]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 2.170e-02]\n",
      " ...\n",
      " [0.000e+00 0.000e+00 1.000e+02 ... 1.000e+00 1.481e+03 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 1.000e+00 0.000e+00 1.778e-01]\n",
      " [0.000e+00 0.000e+00 4.680e+01 ... 5.000e+00 0.000e+00 8.571e-01]]\n"
     ]
    }
   ],
   "source": [
    "df = df.values\n",
    "df = np.array(df)\n",
    "#read the dataform to array\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(23):\n",
    "    df[:,i] = (df[:,i]-df[:,i].min())/(df[:,i].max()-df[:,i].min())\n",
    "#Data normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df[:,:23]\n",
    "y_data = df[:,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the train model\n",
    "x = tf.placeholder(tf.float32,[None,23],name = \"X\")          #24 input \n",
    "y = tf.placeholder(tf.float32,[None,1],name = \"Y\")           # 1 output\n",
    "Weights_L1 = tf.Variable(tf.random_normal([23,20],stddev=0.01))\n",
    "biases_L1 = tf.Variable(tf.zeros([1,20]))\n",
    "Wx_plus_b_L1 = tf.matmul(x,Weights_L1) + biases_L1\n",
    "L1 = tf.tanh(Wx_plus_b_L1)  #activiation founction\n",
    "w = tf.Variable(tf.random_normal([20,1])) #hidden layer\n",
    "b = tf.Variable(tf.zeros([1,20]))\n",
    "Wx_plus_b_L2 = tf.matmul(L1,w) + b\n",
    "pred = tf.nn.relu(Wx_plus_b_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= 0.0 b= [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] w= [[ 1.0343236 ]\n",
      " [-0.23345436]\n",
      " [-0.66320235]\n",
      " [-0.5057406 ]\n",
      " [-1.4873843 ]\n",
      " [-1.2115022 ]\n",
      " [ 1.1697094 ]\n",
      " [-0.03152117]\n",
      " [-1.1380386 ]\n",
      " [ 1.8179114 ]\n",
      " [-1.650698  ]\n",
      " [-0.9362165 ]\n",
      " [ 0.5144368 ]\n",
      " [ 0.12752476]\n",
      " [ 2.236437  ]\n",
      " [ 1.1018323 ]\n",
      " [ 0.20238817]\n",
      " [-1.060732  ]\n",
      " [ 0.90985465]\n",
      " [-0.57679427]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_epochs = 1\n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"LossFunction\"):\n",
    "    loss_function = tf.reduce_mean(tf.pow(y-pred,2))    \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_function)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#init variable\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#run session\n",
    "sess.run(init)\n",
    "\n",
    "#Iterative training\n",
    "for epoch in range(train_epochs):\n",
    "    loss_sum = 0.0\n",
    "    for xs,ys in zip(x_data,y_data):\n",
    "        \n",
    "        xs = xs.reshape(1,23)\n",
    "        ys = ys.reshape(1,1)\n",
    "        _,loss = sess.run([optimizer,loss_function],feed_dict={x:xs,y:ys})\n",
    "\n",
    "    x_data,y_data = shuffle(x_data,y_data)\n",
    "\n",
    "    b0temp = b.eval(session=sess)            \n",
    "    w0temp = w.eval(session=sess)  \n",
    "\n",
    "    loss_average = loss_sum/len(y_data) \n",
    "    \n",
    "    print(\"epoch=\",epoch+1,\"loss=\",loss_average,\"b=\",b0temp,\"w=\",w0temp)\n",
    "#for fastest training, i just set the epoch to 1. But it should be set above 10 to auarantee the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1_raw=pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\n",
    "#load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test1_raw.drop(columns=['Id','groupId','matchId','matchType'])\n",
    "df_test = df_test.values\n",
    "df_test = np.array(df_test)\n",
    "for i in range(23):\n",
    "    df_test[:,i] = (df_test[:,i]-df_test[:,i].min())/(df_test[:,i].max()-df_test[:,i].min())\n",
    "x__data_test = df_test[:,:23]\n",
    "y__data_test = df_test[:,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#calculate the prediction with the model trained before\n",
    "row=len(df_test)\n",
    "pre=np.zeros(row)\n",
    "#create a zero array to save the prediction value\n",
    "for n in range(1,row):\n",
    "    x_test = x__data_test[n]\n",
    "    x_test\n",
    "    x_test = x_test.reshape(1,23)\n",
    "    predict = sess.run(pred,feed_dict={x:x_test})\n",
    "    pre[n]=predict[:,1]\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit=pd.read_csv(\"../input/pubg-finish-placement-prediction/sample_submission_V2.csv\")\n",
    "#load the submission file from kaggle's file folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit['winPlacePerc']=pre\n",
    "#replace the 'winPlacePrec' with prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Id  winPlacePerc\n",
      "0        9329eb41e215eb           0.0\n",
      "1        639bd0dcd7bda8           0.0\n",
      "2        63d5c8ef8dfe91           0.0\n",
      "3        cf5b81422591d1           0.0\n",
      "4        ee6a295187ba21           0.0\n",
      "...                 ...           ...\n",
      "1934169  a316c3a13887d5           0.0\n",
      "1934170  5312146b27d875           0.0\n",
      "1934171  fc8818b5b32ad3           0.0\n",
      "1934172  a0f91e35f8458f           0.0\n",
      "1934173  3696fc9f3a42b2           0.0\n",
      "\n",
      "[1934174 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_submit)\n",
    "#check the format of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('../working/submission.csv',index=None)\n",
    "#save the file to specified path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}